{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the process name to be human readable in htop\n",
    "import setproctitle\n",
    "setproctitle.setproctitle(\"03_Generate_Proteins_Summary\")\n",
    "\n",
    "from config import *\n",
    "from helper_functions import fasta2dict, NWSeqAlignment, alignPrint, batchUniProtAPI\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates a summary of all of the proteins included in the input interaction set and outputs it as Proteins.txt. The primary purpose of this is just to have convenient access to gene names / sequences / lengths for all human UniProt / SARS-CoV-2 protein entries for later analyses and result formatting.\n",
    "\n",
    "- Inputs:\n",
    "  - Interactions.txt\n",
    "  - Covid19_Interactome.txt\n",
    "\n",
    "\n",
    "- Static Resource Dependencies:\n",
    "  - uniprot_info.txt\n",
    "  - pfam_domains.txt\n",
    "  - uniprot_covid_19.fasta\n",
    "\n",
    "\n",
    "- Outputs:\n",
    "  - Proteins.txt\n",
    "  - Protein_Domains.txt\n",
    "\n",
    "\n",
    "- Dependencies:\n",
    "  - Should be run AFTER all interacitons have been fed through ECLAIR pipeline for interface prediction\n",
    "    - **NOTE:** The ECLAIR pipeline is not incluuded in this repository, and treats any output from this pipeline as a static result that is already available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Info for Human / Viral Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This script is based on some hardcoded local resources\n",
    "#       that are not updated by the code provided here. Specifically\n",
    "#       the \"uniprot_info.txt\" is generated during the steps of our\n",
    "#       ECLAIR pipeline.\n",
    "#       \n",
    "#       Any such resources / pre-requisites that cannot be reconstructed\n",
    "#       from scratch from this repository are included in the \"statis_resources\"\n",
    "#       directory. Inquiries for reconstructing or updating any of these files\n",
    "#       can be addressed to Shayne Wierbowski (sdw95@cornell.edu). If there is\n",
    "#       sufficient interest, this code can be made available as a separate repository,\n",
    "#       but is currently highly integrated into our local servers and difficult to\n",
    "#       compartmentalize for public use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniprot Info Generated in ECLIAR\n",
    "uniprot_info = pd.read_csv(\"{0}/uniprot_info.txt\".format(resource_dir), sep=\"\\t\")\n",
    "\n",
    "# Original Interaction List from Krogan Paper (Gordon et al Nature 2020, Supplementary Table 2)\n",
    "# Available at - https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-020-2286-9/MediaObjects/41586_2020_2286_MOESM6_ESM.xlsx\n",
    "# \n",
    "# NOTE: This table really just used to conveniently grab human gene symbols, and (this format) is not technically\n",
    "#       necessary if this code were modified for other interaction sets\n",
    "interactions = pd.read_csv(\"{0}/COVID19_Interactome.txt\".format(input_dir), sep=\"\\t\")\n",
    "id2gene = interactions.set_index(\"Preys\")[\"PreyGene\"].to_dict() # Map Human UniProt to Prefered Gene Name\n",
    "\n",
    "# Generate Full Set of Identifiers submitted to ECLIAR\n",
    "#\n",
    "# NOTE: This is the primary input that mattersr (tab separated list of interaction based on UniProt ID)\n",
    "#       (Although since UniProt IDs were not available for SARS-CoV-2 proteins at the onset of this project\n",
    "#        we've used a custom set of names throughput)\n",
    "interactions2 = pd.read_csv(\"{0}/Interactions.txt\".format(input_dir), sep=\"\\t\")\n",
    "all_ids = set(interactions2[\"P1\"].to_list() + interactions2[\"P2\"].to_list())\n",
    "\n",
    "# Pull out / Reformat the lines in UniProt Info we care about\n",
    "protein_summary = uniprot_info[uniprot_info[\"id\"].map(lambda x: x in all_ids)][[\"id\", \"reviewed\", \"genes\", \"protein names\", \"length\", \"sequence\"]]\n",
    "protein_summary[\"Is_Viral\"] = protein_summary[\"id\"].map(lambda x: \"COVID\" in x)\n",
    "protein_summary[\"reviewed\"] = protein_summary[[\"id\", \"reviewed\"]].apply(lambda x: True if x[1] == \"reviewed\" and not \"COVID\" in x[0] else False, axis=1)\n",
    "protein_summary[\"genes\"] = protein_summary[[\"id\", \"genes\"]].apply(lambda x: x[1] if not x[0] in id2gene else id2gene[x[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "#protein_summary.sort_values([\"Is_Viral\", \"genes\"])[[\"id\", \"Is_Viral\", \"reviewed\", \"genes\", \"protein names\", \"length\", \"sequence\"]]\n",
    "protein_summary.sort_values([\"Is_Viral\", \"genes\"])[[\"id\", \"Is_Viral\", \"genes\", \"length\", \"sequence\"]].to_csv(\"{0}/Proteins.txt\".format(output_dir), sep=\"\\t\", header=[\"ID\", \"Is_Viral\", \"Gene_Name\", \"Length\", \"Sequence\"], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Human UniProt Domain Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: pfam_domain data also pulled from ECLAIR pipeline rather than generated from scratch\n",
    "#       This data only for internal use and is intended for part of the web display. Should not\n",
    "#       be relevant to the main pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ECLAIR Domain Info\n",
    "pfam_doms = pd.read_csv(\"{0}/pfam_domains.txt\".format(resource_dir), names=[\"ID\", \"Is_Domain\"], sep=\"\\t\")\n",
    "pfam_doms = pfam_doms[pfam_doms[\"ID\"].map(lambda x: x in all_ids)]\n",
    "\n",
    "pfam_doms[\"Is_Viral\"] = pfam_doms[\"ID\"].map(lambda x: \"COVID\" in x)\n",
    "\n",
    "pfam_doms.sort_values([\"Is_Viral\", \"ID\"])[[\"ID\", \"Is_Viral\", \"Is_Domain\"]].to_csv(\"{0}/Protein_Domains.txt\".format(output_dir), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add COVID UniProt IDs to Protein Info where Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-read Protein summary\n",
    "proteins = pd.read_csv(\"{0}/Proteins.txt\".format(output_dir), sep=\"\\t\")\n",
    "\n",
    "# Read local covid19 uniprot fasta\n",
    "# This was just a download through the UniProt\n",
    "# COVID19 resource (https://covid-19.uniprot.org/uniprotkb?query=*)\n",
    "covid_fasta = fasta2dict(\"{0}/uniprot_covid_19.fasta\".format(resource_dir))\n",
    "\n",
    "# This fasta includes human / SARS1 entries as well. Filter to only the SARS2 entries\n",
    "covid_fasta = {k.split(\"|\")[1]:v for k, v in covid_fasta.iteritems() if \"OX=2697049\" in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9d1ddb67e4414a989f611baa4acdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/|/ 93%|| 333/359 [00:20<00:01, 15.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Select most the best matched SARS-CoV-2 entry (provided by us) for each\n",
    "# UniProt SARS-CoV-2 entry\n",
    "covid2best = defaultdict(lambda: [\"None\", {\"Pident\":0}])\n",
    "\n",
    "# Iterate over our IDs\n",
    "for uniA, seqA in tqdm_notebook(proteins[[\"ID\", \"Sequence\"]].values):\n",
    "    # Skip the human proteins\n",
    "    if(not \"COVID19\" in uniA):\n",
    "        continue\n",
    "    \n",
    "    # Iterate over the Uniprot IDs\n",
    "    for uniB, seqB in covid_fasta.iteritems():\n",
    "        # Manually selected which UniProt should be used for orf8 (based on visual inspection of alignments)\n",
    "        if((uniA == \"orf8\") and not uniB == \"P0DTC8\"):\n",
    "            continue\n",
    "        \n",
    "        # Generate alignment, save this entry if it the best so far\n",
    "        align = NWSeqAlignment(seqB, seqA)\n",
    "        if(align[\"Pident\"] > covid2best[uniB][1][\"Pident\"]):\n",
    "            covid2best[uniB] = [uniA, align]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P0DTC7 COVID19orf7a 0\n",
      "A0A663DJA2 COVID19orf10 0\n",
      "P0DTC6 COVID19orf6 0\n",
      "P0DTC9 COVID19N 0\n",
      "P0DTD2 COVID19orf9b 0\n",
      "P0DTD3 COVID19orf9c 0\n",
      "P0DTC5 COVID19M 0\n",
      "P0DTC4 COVID19E 0\n",
      "P0DTC3 COVID19orf3a 0\n",
      "P0DTC2 COVID19Spike 0\n",
      "P0DTC1 COVID19nsp1 4225\n",
      "P0DTD8 COVID19Spike 1252\n",
      "P0DTD1 COVID19nsp1 6916\n",
      "P0DTC8 COVID19orf8 1\n",
      "P0DTC8\n",
      "P0DTC8:         1 MKFLVFLGII TTVAAFHQEC SLQSCTQHQP YVVDDPCPIH FYSKWYIRVG ARKSAPLIEL 60  \n",
      "                  |||||||||| |||||||||| |||||||||| |||||||||| |||||||||| ||||||||||     \n",
      "COVID19orf8:    1 MKFLVFLGII TTVAAFHQEC SLQSCTQHQP YVVDDPCPIH FYSKWYIRVG ARKSAPLIEL 60  \n",
      "\n",
      "P0DTC8:        61 CVDEAGSKSP IQYIDIGNYT VSCLPFTINC QEPKLGSLVV RCSFYEDFLE YHDVRVVLDF 120 \n",
      "                  |||||||||| |||||||||| |||-|||||| |||||||||| |||||||||| ||||||||||     \n",
      "COVID19orf8:   61 CVDEAGSKSP IQYIDIGNYT VSCSPFTINC QEPKLGSLVV RCSFYEDFLE YHDVRVVLDF 120 \n",
      "\n",
      "P0DTC8:       121 I 121 \n",
      "                  |     \n",
      "COVID19orf8:  121 I 121 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now from these select the best UniProt ID to match up with our IDs\n",
    "\n",
    "# Black list to exclude certain Uniprot IDs from the mapping\n",
    "# - P0DTD8 - orf7b (not included in our set)\n",
    "# - P0DTC1 and P0DTD1 - Describe the uncleave replicate proteins (we have the cleaved proteins in our dataset)\n",
    "blacklist = [\"P0DTD8\", \"P0DTC1\", \"P0DTD1\"]\n",
    "krogan2uni = defaultdict(str)\n",
    "for uni, v in covid2best.iteritems():\n",
    "    uniB, align = v\n",
    "    \n",
    "    # Print number of non-identical matches in the alignments\n",
    "    print uni, uniB, len(align[\"Alignment\"].replace(\"|\", \"\"))\n",
    "    if(not uni in blacklist):\n",
    "        krogan2uni[uniB] = uni\n",
    "        \n",
    "        # If the alignment isn't perfect take a look at it\n",
    "        if(align[\"Pident\"] < 1):\n",
    "            print uni\n",
    "            my.alignPrint(align, name1=uni, name2=uniB)\n",
    "\n",
    "proteins[\"UniProt\"] = proteins[\"ID\"].map(lambda x: krogan2uni[x] if \"COVID\" in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the gene names for all UniProt IDs\n",
    "s = proteins[\"UniProt\"].to_list()\n",
    "tmp = dict(zip(s, batchUniProtAPI(s, source_id=\"ACC\", target_id=\"GENENAME\")))\n",
    "proteins[\"Gene Name\"] = proteins[[\"ID\", \"UniProt\"]].apply(lambda x: tmp[x[1]] if not \"COVID\" in x[0] else x[0].replace(\"COVID19\", \"\").replace(\"orf9c\", \"orf14\").replace(\"Spike\", \"S\").replace(\"C145A\", \"\").upper(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final output\n",
    "proteins.to_csv(\"{0}/Proteins.txt\".format(output_dir), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
