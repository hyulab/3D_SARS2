{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the process name to be human readable in htop\n",
    "import setproctitle\n",
    "setproctitle.setproctitle(\"05_Fetch_Population_Variants\")\n",
    "\n",
    "from config import *\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fetches all known population variants for the human interactors included in Proteins.txt using the GnomAD API. Then (requiring some manual input) these variants are mapped through the Variant Effect Predictor (VEP) to get corresponding UniProt positions / other information.\n",
    "\n",
    "**NOTE:** When returning to this step to reformat the code for this repository I encountered a lot of errors because some of the external API's and tools that I used seem to have changed since I originally ran the code. I've reproduced the original workflow as best as possible, but still encounter some troubles I did not originally encounter with genes failing the GnomAD API query. The example output from this notebook included in this repository is just a sub-set of my original population variants list for the human genes included in the demo interacitons list. Results could vary if you try to reproduce this from scratch.\n",
    "\n",
    "- Inputs:\n",
    "  - Proteins.txt\n",
    "\n",
    "\n",
    "- Outputs:\n",
    "  - VEP_Input.txt\n",
    "  - Human_Population_Variants_VEP_Mapped.txt\n",
    "  - Pop_Vars.txt\n",
    "\n",
    "\n",
    "- Dependencies:\n",
    "  - Must be run after 03_Generate_Proteins_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query GnomAD for Population Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed From https://gist.github.com/ressy/6fd7f6ee6401ac8e703dc2709399869e\n",
    "# See also Docs at (https://gnomad.broadinstitute.org/api)\n",
    "def fetch_gnomAD(jsondata, url=\"https://gnomad.broadinstitute.org/api\"):\n",
    "    # The server gives a generic error message if the content type isn't\n",
    "    # explicitly set\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(url, json=jsondata, headers=headers)\n",
    "    json = response.json()\n",
    "    if \"errors\" in json:\n",
    "        raise Exception(str(json[\"errors\"]))\n",
    "    return json\n",
    "# FUNCTION END\n",
    "\n",
    "# Borrowed From https://gist.github.com/ressy/6fd7f6ee6401ac8e703dc2709399869e\n",
    "# See also Docs at (https://gnomad.broadinstitute.org/api)\n",
    "def queryGnomadByGene(gene_name, dataset=\"gnomad_r2_1\", fields=[\"gene_id\", \"gene_symbol\", \"chrom\", \"pos\", \"ref\", \"alt\", \"consequence\", \"rsid\", \"variantId\", \"hgvsp\"]):\n",
    "    # Note that this is GraphQL, not JSON.\n",
    "    fmt_graphql = \"\"\"\n",
    "    {\n",
    "        gene(gene_symbol: \"%s\", reference_genome:GRCh38) {\n",
    "          variants(dataset: %s) {\n",
    "          %s\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # This part will be JSON encoded, but with the GraphQL part left as a\n",
    "    # glob of text.\n",
    "    req_variantlist = {\n",
    "        \"query\": fmt_graphql % (gene_name, dataset, \"\\n\".join(fields)),\n",
    "        \"variables\": {}\n",
    "        }\n",
    "    response = fetch_gnomAD(req_variantlist)\n",
    "    return pd.DataFrame(response[\"data\"][\"gene\"][\"variants\"])[fields]\n",
    "# FUNCTION END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all Human Proteins Involved in Interactome\n",
    "all_proteins = pd.read_csv(\"{0}/Proteins.txt\".format(output_dir), sep=\"\\t\")\n",
    "human_genes = all_proteins[all_proteins[\"Is_Viral\"] == False][\"Gene_Name\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Attempt 1 with 0 Genes Parsed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e962d43eb79f45aeab9e84318a43cd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ARF6\n",
      "Skipped DDX21\n",
      "Skipped PIGO\n",
      "Skipped SLC27A2\n",
      "Skipped SLC44A2\n",
      "\n",
      "Finished Attempt 1 with 5 Genes Parsed ( 5  New)\n",
      "\n",
      "Starting Attempt 2 with 5 Genes Parsed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ee3ca9796f43b7a443a3de80d1c82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ARF6\n",
      "Skipped DDX21\n",
      "\n",
      "Finished Attempt 2 with 8 Genes Parsed ( 3  New)\n",
      "\n",
      "Starting Attempt 3 with 8 Genes Parsed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d203842df684478da3dd93abcc0cdd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ARF6\n",
      "Skipped DDX21\n",
      "\n",
      "Finished Attempt 3 with 8 Genes Parsed ( 0  New)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-482f9422d23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mattempt_i\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;31m#all_variants = pd.concat(all_variants)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fetch All Variants Listed in gnomAD (filter to only missense variants)\n",
    "# NOTE: There is a query rate limit exceeded error that gets thrown if you submit\n",
    "#       too many requests at once. I've jerry rigged this to just keep trying\n",
    "#       until it works. But the first time I ran it, this worked fine on one attempt.\n",
    "#\n",
    "# NOTE: AATF and CISD3 never finish with the current setup (they throw a separate error, no data\n",
    "#       in gnomad_r2_1?). These weren't a problem when I ran using GRCh37 as the reference genome\n",
    "#       instead of GRCh38. Comparing the two outputs, the chromosomal positions don't seem to actually\n",
    "#       change depending on the reference genome selected so I'm not sure what this means. When\n",
    "#       this code was run originally, the GnomAD API didn't require a reference_genome selection.\n",
    "\n",
    "import time\n",
    "all_variants = dict()\n",
    "\n",
    "attempt_i = 1\n",
    "attempts_per_gene = 10\n",
    "while(True):\n",
    "    cur_keys = len(all_variants)\n",
    "    if(cur_keys == len(human_genes)):\n",
    "        break\n",
    "    print \"Starting Attempt\", attempt_i, \"with\", cur_keys, \"Genes Parsed\"\n",
    "    \n",
    "    # Iterate over all genes\n",
    "    for g in tqdm_notebook(human_genes):\n",
    "        if(g in all_variants):\n",
    "            continue\n",
    "        \n",
    "        # Try to fetch variants on each gene n times\n",
    "        tries = 0\n",
    "        while(True):\n",
    "            try:\n",
    "                tries += 1\n",
    "                pop_variants = queryGnomadByGene(g)\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(0.1)\n",
    "                if(tries > attempts_per_gene):\n",
    "                    break\n",
    "                pass\n",
    "        if(tries > attempts_per_gene):\n",
    "            print \"Skipped\", g\n",
    "            continue\n",
    "        if(not g == pop_variants[\"gene_symbol\"].unique()[0]):\n",
    "            print \"MISMATCH: \", g, \"-->\", pop_variants[\"gene_symbol\"].unique()[0]\n",
    "            pop_variants[\"gene_symbol\"] = g\n",
    "        all_variants[g] = pop_variants[pop_variants[\"consequence\"] == \"missense_variant\"]\n",
    "    \n",
    "    print \"Finished Attempt\", attempt_i, \"with\", len(all_variants), \"Genes Parsed (\", (len(all_variants) - cur_keys), \" New)\"\n",
    "    print\n",
    "    attempt_i += 1\n",
    "    time.sleep(60)\n",
    "#all_variants = pd.concat(all_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Variants for each gene into one DF\n",
    "all_variants = pd.concat(all_variants.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2720\n",
      "2720\n"
     ]
    }
   ],
   "source": [
    "# Sort and remove duplicates (no longer necessary?)\n",
    "# (for some reason POL1A had duplicate entries?)\n",
    "# (Could not reproduce, but GnomAD API syntax has also changed since first run)\n",
    "print len(all_variants[all_variants.duplicated([\"chrom\", \"pos\", \"ref\", \"alt\"], keep=False)])\n",
    "\n",
    "all_variants[\"chrom\"] = all_variants[\"chrom\"].map(lambda x: int(x) if not x == \"X\" else x)\n",
    "print len(all_variants)\n",
    "all_variants = all_variants.drop_duplicates().sort_values([\"chrom\", \"pos\", \"ref\", \"alt\"])\n",
    "print len(all_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Variants to UniProt Position using VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This step can most easilly be done by manually querying VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Input File for VEP\n",
    "out = open(\"{0}/VEP_Input.txt\".format(output_dir), \"w+\")\n",
    "out.write(\"\\n\".join(all_variants[[\"chrom\", \"pos\", \"ref\", \"alt\"]].apply(lambda x: \"{0} {1} . {2} {3}\".format(*x), axis=1)))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Either I'm crazy or there's currently something up with VEP\n",
    "#       When submitting to the grch37 version the SWISSPROT column\n",
    "#       in the output only shows gene names (e.g. PARP_HUMAN) so the\n",
    "#       text download cannnot be used to map UniProt IDs (this is part\n",
    "#       of the sanity check I use to make sure the mapping is verifiable)\n",
    "#\n",
    "#       Instead of just submitting to the grch37 like I did originally.\n",
    "#\n",
    "#       (https://grch37.ensembl.org/Homo_sapiens/Tools/VEP)\n",
    "#\n",
    "#       I instead now need to re-map the GnomAD vairants (only provided in\n",
    "#       grch37 coordinates) to grch38 using the ensembl assembly converter\n",
    "#\n",
    "#       (https://grch37.ensembl.org/Homo_sapiens/Tools/AssemblyConverter?db=core)\n",
    "#\n",
    "#       Then submit the mapped input to the regular grch38 VEP\n",
    "#\n",
    "#       (https://useast.ensembl.org/Homo_sapiens/Tools/VEP?)\n",
    "#\n",
    "#       This then becomes a pain because merging the VEP output (GRCh38) with\n",
    "#       the original GnomAD (GRCh37) input is not straightforward. The Ensembl\n",
    "#       assembly converrter drops some variants during the conversion without\n",
    "#       indicating which ones are dropped so a 1-1 mapping based on order\n",
    "#       is not possible.\n",
    "#       \n",
    "#       Rather than updating and re-runing this script I'm just defaulting to the\n",
    "#       output from the previously working version of this code / external resources.\n",
    "\n",
    "# Submit input file here...\n",
    "#\n",
    "# https://grch37.ensembl.org/Homo_sapiens/Tools/VEP\n",
    "#\n",
    "# Additional Configurations\n",
    "#\n",
    "# - Identifiers\n",
    "#   + Gene Symbol\n",
    "#   + Transcript version\n",
    "#   + UniProt (not selected by default)\n",
    "#\n",
    "# - Variants and Frequency Data\n",
    "#   + Find co-located known variants (Yes)\n",
    "#   + Frequency Data for co-located variants\n",
    "#     - 1000 Genomes global MAF\n",
    "#     - gnomAD exomes (not selected by default)\n",
    "#   + PubMedIDs for citations (Yes)\n",
    "#\n",
    "# - Additional Annotations\n",
    "#   + Default options\n",
    "#\n",
    "# - Predictions\n",
    "#   + Default options (SIFT + PolyPhen prediction and score)\n",
    "#\n",
    "# Filtering Options\n",
    "#   + Defualt\n",
    "#\n",
    "# Advanced Options\n",
    "#   + Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in VEP Mapped Variants\n",
    "# Download output from VEP job\n",
    "# NOTE: From results papge apply filter \"Uploaded variant is missense_variant\"\n",
    "#       to limit to only relevant entries\n",
    "#\n",
    "# Save in root project directory and rename to match filename below...\n",
    "vep_mapped = pd.read_csv(\"{0}/Human_Population_Variants_VEP_Mapped.txt\".format(output_dir), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Join on Key\n",
    "vep_mapped[\"Key\"] = vep_mapped[[\"Location\", \"Allele\"]].apply(lambda x: x[0].split(\"-\")[0] + x[1], axis=1)\n",
    "all_variants[\"Key\"] = all_variants[[\"chrom\", \"pos\", \"alt\"]].apply(lambda x: str(x[0]) + \":\" + str(x[1]) + x[2], axis=1)\n",
    "\n",
    "# Make sure the same variants are included in both\n",
    "# NOTE: This should not match anymore because of GRCh37 to GRCh38 mapping step\n",
    "s1 = set(all_variants[\"Key\"])\n",
    "s2 = set(vep_mapped[\"Key\"])\n",
    "print s1 == s2\n",
    "\n",
    "# Merge\n",
    "merged = all_variants.join(vep_mapped.set_index(\"Key\"), how=\"inner\", on=\"Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7616\n",
      "7616\n"
     ]
    }
   ],
   "source": [
    "# Get expected UniProt from original input / compare against VEP Mapping\n",
    "proteins = pd.read_csv(\"{0}/Proteins.txt\".format(output_dir), sep=\"\\t\")\n",
    "gene2uniprot = proteins.set_index(\"Gene_Name\")[\"ID\"].to_dict()\n",
    "merged[\"Expected_UniProt\"] = merged[\"gene_symbol\"].map(lambda x: gene2uniprot[x])\n",
    "\n",
    "# Drop any cases with wrong UniProt mapping (there are only 2 here so its not a big deal)\n",
    "print len(merged)\n",
    "print len(merged[merged[\"SWISSPROT\"] == merged[\"Expected_UniProt\"]])\n",
    "merged = merged[merged[\"SWISSPROT\"] == merged[\"Expected_UniProt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select / Rename Columns\n",
    "merged[\"AA_Ref\"] = merged[\"Amino_acids\"].map(lambda x: x.split(\"/\")[0])\n",
    "merged[\"AA_Alt\"] = merged[\"Amino_acids\"].map(lambda x: x.split(\"/\")[1])\n",
    "merged[\"SIFT_Category\"] = merged[\"SIFT\"].map(lambda x: x.split(\"(\")[0] if not x == \"-\" else np.nan)\n",
    "merged[\"SIFT_Score\"] = merged[\"SIFT\"].map(lambda x: float(x.split(\"(\")[1].strip(\")\")) if not x == \"-\" else np.nan)\n",
    "merged[\"PolyPhen_Category\"] = merged[\"PolyPhen\"].map(lambda x: x.split(\"(\")[0] if not x == \"-\" else np.nan)\n",
    "merged[\"PolyPhen_Score\"] = merged[\"PolyPhen\"].map(lambda x: float(x.split(\"(\")[1].strip(\")\")) if not x == \"-\" else np.nan)\n",
    "merged = merged[[\"gene_symbol\", \"gene_id\", \"SWISSPROT\", \"chrom\", \"pos\", \"ref\", \"alt\", \"consequence\", \"rsid\", \"IMPACT\", \"Protein_position\", \"AA_Ref\", \"AA_Alt\", \"SIFT_Category\", \"SIFT_Score\", \"PolyPhen_Category\", \"PolyPhen_Score\", \"gnomAD_AF\", \"CLIN_SIG\", \"SOMATIC\", \"PHENO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "merged.columns = [\"Gene_Symbol\", \"Gene_ID\", \"UniProt\", \"Chrom\", \"Pos\", \"Ref\", \"Alt\", \"Consequence\", \"rsID\", \"Imact\", \"AA_Pos\", \"AA_Ref\", \"AA_Alt\", \"SIFT_Category\", \"SIFT_Score\", \"PolyPhen_Category\", \"PolyPhen_Score\", \"gnomAD_AF\", \"Clinical_Significance\", \"Somatic\", \"Pheno\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update gnomAD_AF to remove \"-\" blanks\n",
    "merged[\"gnomAD_AF\"] = merged[\"gnomAD_AF\"].map(lambda x: float(x) if not x == \"-\" else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all mapped uniprot positions references match\n",
    "protein_summary = pd.read_csv(\"{0}/Proteins.txt\".format(output_dir), sep=\"\\t\")\n",
    "uni2seq = protein_summary.set_index(\"ID\")[\"Sequence\"].to_dict()\n",
    "merged[\"Accurate_Pos\"] = merged[[\"UniProt\", \"AA_Pos\", \"AA_Ref\"]].apply(lambda x: uni2seq[x[0]][x[1] - 1] == x[2] if x[1] <= len(uni2seq[x[0]]) else False, axis=1)\n",
    "\n",
    "tmp = merged.sort_values([\"Chrom\", \"Pos\", \"Accurate_Pos\"], ascending=[True, True, False]).drop_duplicates([\"Chrom\", \"Pos\", \"Ref\", \"Alt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867042707493956"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"Accurate_Pos\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2482"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2720"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain variants where the reference matches at the Uniprot position\n",
    "tmp = tmp[tmp[\"Accurate_Pos\"]]\n",
    "tmp = tmp.drop(\"Accurate_Pos\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final list of population variants\n",
    "tmp.to_csv(\"{0}/Pop_Vars.txt\".format(output_dir), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
