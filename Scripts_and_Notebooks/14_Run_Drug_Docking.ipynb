{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the process name to be human readable in htop\n",
    "import setproctitle\n",
    "setproctitle.setproctitle(\"14_Run_Drug_Docking\")\n",
    "\n",
    "from config import *\n",
    "from helper_functions import zip_res_range, unzip_res_range, flatten, pdb2df, df2pdb\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "import subprocess as sp\n",
    "import time\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook first parses a provided list of candidate drugs that target one or more human interactors of SARS-CoV-2 (this is a static input, but this setup could theoretically be generalized to any list of protein-drug pairs). Then protein-ligand docking for each pair is run in smina and the top-ranked docked conformation from each pair is retained.\n",
    "\n",
    "\n",
    "- Inputs:\n",
    "  - Krogan_Drug_Candidates.txt\n",
    "  - COVID_19_Interactome.txt\n",
    "  - Models.txt\n",
    "  - Proteins.txt\n",
    "  - [Prot]\\_[Source].pdb (Undocked Structures)\n",
    "\n",
    "\n",
    "- Outputs:\n",
    "  - [Drug].pdb (Undocked Drug Structures)\n",
    "  - [Drug].svg (2D Image of Drug Structure)\n",
    "  - [P1]\\_[Drug].pdb (top ranked drug docking for each protein-drug pair)\n",
    "\n",
    "\n",
    "- Dependencies:\n",
    "  - Must be run after 04_Select_Models\n",
    "  - Must have smina installed locally (available through conda)\n",
    "  - Must have openbabel installed locally (available through conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and Clean Drug List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded from Gordon et al Nature 2020 Supplemental Data\n",
    "# https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-020-2286-9/MediaObjects/41586_2020_2286_MOESM9_ESM.xlsx\n",
    "drugs = pd.read_csv(\"{0}/Krogan_Drug_Candidates.txt\".format(input_dir), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean entries with multiple gene names in one row\n",
    "# Based on manual inspection of all cases\n",
    "rows = []\n",
    "for row in drugs.values:\n",
    "    row = list(row)\n",
    "    \n",
    "    # Simple case, multiple genes separated by slash\n",
    "    if(\"/\" in row[1]):\n",
    "        targets = row[1].split(\"/\")\n",
    "        if(len(targets[1]) <= 2):\n",
    "            targets = (targets[0], targets[0][:-1] + targets[-1])\n",
    "            targets = [x if x != \"EIF4EH\" else \"EIF4H\" for x in targets]\n",
    "        else:\n",
    "            pass\n",
    "    # Special case for genes separated by space\n",
    "    elif(\" \" in row[1]):\n",
    "        # Separate out \"NUPs RAE1\" entry to include\n",
    "        # all NUP proteins + RAE1\n",
    "        if(\"NUPs\" in row[1]):\n",
    "            targets = ['NUP210', 'NUP214', 'NUP62', 'NUP54', 'NUP88', 'NUP58', 'NUP98', 'RAE1']\n",
    "        else:\n",
    "            targets = [row[1]]\n",
    "    # These are mostly groups of gene described by function (e.g. \"Cell Entry\")\n",
    "    # We ignore these, but there are also a handful of genes with extra spaces\n",
    "    # in the gene name.\n",
    "    else:\n",
    "        targets = [row[1].strip()]\n",
    "    # Special case to interpret NDUFs as all NDUF Proteins\n",
    "    if(targets == [\"NDUFs\"]):\n",
    "        targets = [\"NDUFAF2\", \"NDUFAF1\", \"NDUFB9\"]\n",
    "    \n",
    "    # Flatten table for separate rows for all targets\n",
    "    targets = set(flatten([x.strip().split(\"\\n\") for x in targets]))\n",
    "    for t in targets:\n",
    "        rows.append([row[0], t] + row[2:])\n",
    "drugs = pd.DataFrame(rows, columns=list(drugs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match by human interacting gene name\n",
    "interactions = pd.read_csv(\"{0}/COVID19_Interactome.txt\".format(input_dir), sep=\"\\t\")\n",
    "\n",
    "m = drugs.join(interactions.set_index(\"PreyGene\"), on=\"Human Gene\", how=\"inner\")\n",
    "\n",
    "# Select / Rename columns and save\n",
    "m = m[[\"Compound Name\", \"Human Gene\", \"Preys\", \"Bait\", \"Structures (PDB)\", \"Drug Status\", \"Activity Description\", \"Activity Description.1\", \"Reference\", \"Smiles\", \"ZINC_ID\", \"Purchase notes\", \"Source\"]]\n",
    "m.columns = [\"Compound Name\", \"Human Gene\", \"Human ID\", \"Viral ID\", \"Human PDBs\", \"Drug Status\", \"Activity Type\", \"Activity\", \"Reference\", \"Smiles\", \"ZINC_ID\", \"Purchase Notes\", \"Source\"]\n",
    "\n",
    "m.to_csv(\"{0}/Krogan_Drug_Candidates.txt\".format(output_dir), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate PDB files for each ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.exists(\"{0}/Ligands\".format(output_dir))):\n",
    "    os.mkdir(\"{0}/Ligands\".format(output_dir))\n",
    "if(not os.path.exists(\"{0}/Ligands/Images\".format(output_dir))):\n",
    "    os.mkdir(\"{0}/Ligands/Images\".format(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0596a5fda8fd489c80487d49170986ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=69), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, smiles in tqdm_notebook(drugs.drop_duplicates([\"Compound Name\"])[[\"Compound Name\", \"Smiles\"]].values):\n",
    "    # This SMILES String is improperly formatted. I looked up the \"correct\" string here...\n",
    "    # https://www.medchemexpress.com/dBET6.html?src=google-product&gclid=EAIaIQobChMIqYf5m5ul6QIVT8DICh20VQh-EAAYASAAEgLmkPD_BwE\n",
    "    if(name == \"dBET6\"):\n",
    "        smiles = \"O=C(NCCCCCCCCNC(COC1=CC=CC(C(N2C(CC3)C(NC3=O)=O)=O)=C1C2=O)=O)C[C@H]4C5=NN=C(C)N5C6=C(C(C)=C(C)S6)C(C7=CC=C(Cl)C=C7)=N4\"\n",
    "    \n",
    "    # Use OpenBabel to create PDB File\n",
    "    print os.system(\"obabel -:\\\"{0}\\\" --gen3d -opdb -O {1}/Ligands/{2}.pdb -d\".format(smiles, output_dir, name.replace(\"-\", \"_\").replace(\" \", \"_\").split(\"(\")[0]))\n",
    "    \n",
    "    # Use OpenBabel to create 2D svg image of ligand\n",
    "    print os.system(\"obabel -:\\\"{0}\\\" --gen3d -osvg -O {1}/Ligands/Images/{2}.svg -d\".format(smiles, output_dir, name.replace(\"-\", \"_\").replace(\" \", \"_\").split(\"(\")[0]))\n",
    "    #os.system(\"obabel -i pdb {0} -o pdb -O {0} -d\".format(smiles, name.replace(\"-\", \"_\").replace(\" \", \"_\").split(\"(\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Number of Potentially Dockable Examples\n",
    "# with specific (viral-prot, human-prot, drug) pairs\n",
    "# (Cases where Viral ID is NaN have non-specific human\n",
    "# drug target specified (e.g. \"Viral Transcription\"))\n",
    "len(m[~pd.isnull(m[\"Viral ID\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Undocked Structures for Docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8fec426e8c41f4aa7747c81f04bc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure there are no hydrogens in the protein structures\n",
    "# used for docking\n",
    "for f in tqdm_notebook(glob.glob(\"{0}/Undocked_Structures/*\".format(output_dir))):\n",
    "    os.system(\"obabel -i pdb {0} -o pdb -O {0} -d\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Ligand Docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.exists(\"{0}/Docked_Ligands\".format(output_dir))):\n",
    "    os.mkdir(\"{0}/Docked_Ligands\".format(output_dir))\n",
    "if(not os.path.exists(\"{0}/Docked_Ligands/sub_batches/\".format(output_dir))):\n",
    "    os.mkdir(\"{0}/Docked_Ligands/sub_batches/\".format(output_dir))\n",
    "if(not os.path.exists(\"{0}/Docked_Ligands/ranked_poses/\".format(output_dir))):\n",
    "    os.mkdir(\"{0}/Docked_Ligands/ranked_poses/\".format(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in list of drug pairs\n",
    "drug_pairs = pd.read_csv(\"{0}/Krogan_Drug_Candidates.txt\".format(output_dir), sep=\"\\t\")\n",
    "\n",
    "# Read in model info\n",
    "models = pd.read_csv(\"{0}/Models.txt\".format(output_dir), sep=\"\\t\")\n",
    "\n",
    "# Read in Protein info for total sequence length\n",
    "proteins = pd.read_csv(\"{0}/Proteins.txt\".format(output_dir), sep=\"\\t\")\n",
    "uni2seq = proteins.set_index(\"ID\")[\"Sequence\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d572d90206ae40449f39ab7f3cf43f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smina -r /home/sdw95/3D_SARS2/git_hub/3D_SARS2/Output/Undocked_Structures/P12268_6UAJ_A.pdb -l /home/sdw95/3D_SARS2/git_hub/3D_SARS2/Output/Ligands/Sanglifehrin_A.pdb --autobox_ligand /home/sdw95/3D_SARS2/git_hub/3D_SARS2/Output/Undocked_Structures/P12268_6UAJ_A.pdb --autobox_add 10 -o /home/sdw95/3D_SARS2/git_hub/3D_SARS2/Output/Docked_Ligands/P12268_Sanglifehrin_A.pdb --exhaustiveness 8 --num_modes 10 --cpu 1\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Test loop for running docking with one process at a time\n",
    "# NOTE: For now we just use this to get a summary of how\n",
    "#       many docks will be run, and run the main batch\n",
    "#       in parallel.\n",
    "\n",
    "undockable = []\n",
    "low_coverage = []\n",
    "docked = []\n",
    "for drug, uni in tqdm_notebook(drug_pairs[~pd.isnull(drug_pairs[\"Human ID\"])][[\"Compound Name\", \"Human ID\"]].values):\n",
    "    drug = drug.replace(\"-\", \"_\").replace(\" \", \"_\").split(\"(\")[0]\n",
    "    \n",
    "    # Grap Drug PDB\n",
    "    drug_f = glob.glob(\"{0}/Ligands/{1}*\".format(output_dir, drug))[0]\n",
    "    \n",
    "    # Grab Human Protein PDB (skip if no PDB available)\n",
    "    try:\n",
    "        uni_f = glob.glob(\"{0}/Undocked_Structures/{1}*\".format(output_dir, uni))[0]\n",
    "    except IndexError:\n",
    "        print uni, drug\n",
    "        undockable.append((drug, uni))\n",
    "        continue\n",
    "    \n",
    "    # Check coverage of selected Human PDB\n",
    "    # NOTE: Assumes only one Human Structure available for\n",
    "    #       each protein\n",
    "    total_len = len(uni2seq[uni])\n",
    "    resi_covered = models[models[\"ID\"] == uni][\"Resi_Covered\"].map(lambda x: len(unzip_res_range(x))).values[0]\n",
    "    coverage = resi_covered / float(total_len)\n",
    "    \n",
    "    # If coverage is low, do not attempt docking\n",
    "    # (would be inaccurate / bias predicted binding site)\n",
    "    if(not coverage >= 0.33):\n",
    "        low_coverage.append((drug, uni))\n",
    "        continue\n",
    "    docked.append((drug, uni))\n",
    "    \n",
    "    if(len(docked) > 1):\n",
    "        continue\n",
    "    \n",
    "    print \"smina -r {0} -l {1} --autobox_ligand {0} --autobox_add 10 -o {2}/Docked_Ligands/{3}_{4}.pdb --exhaustiveness 8 --num_modes 10 --cpu 1\".format(uni_f, drug_f, output_dir, uni, drug)\n",
    "    print os.system(\"smina -r {0} -l {1} --autobox_ligand {0} --autobox_add 10 -o {2}/Docked_Ligands/{3}_{4}.pdb --exhaustiveness 8 --num_modes 10 --cpu 1\".format(uni_f, drug_f, output_dir, uni, drug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print len(undockable)\n",
    "print len(low_coverage)\n",
    "print len(docked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docking Iteration 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c6be4b6e6e41f791c4773d842a0864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ee831837f7436c9c3de5539dca965a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4724082b4119410abf17ab562d873435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bad8b14383c48edacca4ba5860a608b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6a945a92c14a3b949e74ff42349e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4c702ef85547ce9e7e5d8a34b866c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a759a99a1b2439b9a60ef81e186bf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbb7cf181214a80a6927efbb5fc9270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2ed988994c465bb1eef289c25c856c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docking Iteration 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c4727ea14d44d889ce969c4bac9386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Ligand Docking in Loop\n",
    "# For the setup here we want to run N different docking trials for each drug-target pair\n",
    "# producing up to 1000 docked conformations for each trial. We will then merge the results\n",
    "# from all trials and retain the top N poses overall.\n",
    "#\n",
    "# Conceptually there should be no difference between repeating the same job N times, vs.\n",
    "# just changing the exhaustiveness parameter to N*exhaustiveness (and possibly upping the\n",
    "# num_mores parameter as well). We just do it in separate jobs here so that the results\n",
    "# for each drug-target pair come in evenly.\n",
    "#\n",
    "# NOTE: I think the setup here might not be 100% safe for the server. While it's running\n",
    "#       I start getting too many files open errors. (Mainly seems to break the running\n",
    "#       JuPyter server)\n",
    "\n",
    "i_num = 1\n",
    "finished_processes = []\n",
    "processes = []\n",
    "\n",
    "max_processes = 5\n",
    "# For this setup we will do 10 trials per drug-target pair. This could be set arbitrarilly\n",
    "# high or low. From past experience, a single trial should be sufficient to obtain good docking\n",
    "# results. We only increase the number of trials here for added roubustness.\n",
    "for i_num in range(10):\n",
    "    print \"Docking Iteration\", i_num\n",
    "    \n",
    "    # Iterate over all Docking Inputs\n",
    "    for drug, uni in tqdm_notebook(drug_pairs[~pd.isnull(drug_pairs[\"Human ID\"])][[\"Compound Name\", \"Human ID\"]].values):\n",
    "        # If this drug-target pair has already been docked on this iteration in the past, just skip it\n",
    "        if(os.path.exists(\"{0}/Docked_Ligands/sub_batches/{1}_{2}_{3}.pdb\".format(output_dir, uni, drug, i_num))):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Grab Drug PDB\n",
    "        drug = drug.replace(\"-\", \"_\").replace(\" \", \"_\").split(\"(\")[0]\n",
    "        drug_f = glob.glob(\"{0}/Ligands/{1}*\".format(output_dir, drug))[0]\n",
    "        \n",
    "        # Try to Grab Human PDB\n",
    "        try:\n",
    "            uni_f = glob.glob(\"{0}/Undocked_Structures/{1}*\".format(output_dir, uni))[0]\n",
    "        except IndexError:\n",
    "            print uni\n",
    "            continue\n",
    "        \n",
    "        # Check coverage of selected Human PDB\n",
    "        # NOTE: Assumes only one Human Structure available for\n",
    "        #       each protein\n",
    "        total_len = len(uni2seq[uni])\n",
    "        resi_covered = models[models[\"ID\"] == uni][\"Resi_Covered\"].map(lambda x: len(unzip_res_range(x))).values[0]\n",
    "        coverage = resi_covered / float(total_len)\n",
    "        \n",
    "        # If coverage is low, do not attempt docking\n",
    "        # (would be inaccurate / bias predicted binding site)\n",
    "        if(not coverage >= 0.33):\n",
    "            continue\n",
    "        \n",
    "        # Block new jobs if too many running already\n",
    "        while(True):\n",
    "            # If fewer than N (5) jobs running currently, submit next docking job\n",
    "            if(len(processes) <= max_processes):\n",
    "                cmd = \"nice smina -r {0} -l {1} --autobox_ligand {0} --autobox_add 10 -o {2}/Docked_Ligands/sub_batches/{3}_{4}_{5}_in_progress.pdb --exhaustiveness 40 --num_modes 1000 --cpu 5 --seed {5}\".format(uni_f, drug_f, output_dir, uni, drug, i_num)\n",
    "                p = sp.Popen(cmd, shell=True)\n",
    "                processes.append({\"p\":p, \"cmd\":cmd, \"start_time\":time.time(), \"end_time\":None, \"in\":(drug, uni), \"out_f\":\"{0}/Docked_Ligands/sub_batches/{1}_{2}_{3}_in_progress.pdb\".format(output_dir, uni, drug, i_num)})\n",
    "                break\n",
    "            \n",
    "            # Otherwise wait until previous jobs have finished before starting a new docking job\n",
    "            else:\n",
    "                # Sleep for 30 seconds to give processes a change to finish\n",
    "                time.sleep(30)\n",
    "                \n",
    "                # List of actively running processes (to be built)\n",
    "                new_processes = []\n",
    "                \n",
    "                # Iterate over current process list\n",
    "                for p in processes:\n",
    "                    # If the process hasn't exited yet add it back\n",
    "                    # into the list\n",
    "                    if(p[\"p\"].poll() is None):\n",
    "                        new_processes.append(p)\n",
    "                    # Otherwise, if exit code indicates and error\n",
    "                    # print out error message\n",
    "                    elif(p[\"p\"].poll() != 0):\n",
    "                        p[\"end_time\"] = time.time()\n",
    "                        print \"Error\", p[\"p\"].poll()\n",
    "                        print \"cmd:\", p[\"cmd\"]\n",
    "                        print \"RunTime:\", (p[\"end_time\"] - p[\"start_time\"])\n",
    "                        print\n",
    "                        finished_processes.append(p)\n",
    "                    # otherwise, process finished successfully\n",
    "                    # Print out total run-time\n",
    "                    else:\n",
    "                        p[\"end_time\"] = time.time()\n",
    "                        print \"Finished Docking\", p[\"in\"], \"in\", (p[\"end_time\"] - p[\"start_time\"])\n",
    "                        os.system(\"mv {0} {1}\".format(p[\"out_f\"], p[\"out_f\"].replace(\"_in_progress\", \"\")))\n",
    "                        finished_processes.append(p)\n",
    "                \n",
    "                # Update active process list\n",
    "                processes = new_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over remaining processes to finish\n",
    "# NOTE: The main reason this is necessary is because I rename\n",
    "#       the output file after the process is fully done.\n",
    "while(processes):\n",
    "    # Sleep for 30 seconds to give processes a change to finish\n",
    "    time.sleep(30)\n",
    "    \n",
    "    # List of actively running processes (to be built)\n",
    "    new_processes = []\n",
    "    \n",
    "    # Iterate over current process list\n",
    "    for p in processes:\n",
    "        # If the process hasn't exited yet add it back\n",
    "        # into the list\n",
    "        if(p[\"p\"].poll() is None):\n",
    "            new_processes.append(p)\n",
    "        # Otherwise, if exit code indicates and error\n",
    "        # print out error message\n",
    "        elif(p[\"p\"].poll() != 0):\n",
    "            p[\"end_time\"] = time.time()\n",
    "            print \"Error\", p[\"p\"].poll()\n",
    "            print \"cmd:\", p[\"cmd\"]\n",
    "            print \"RunTime:\", (p[\"end_time\"] - p[\"start_time\"])\n",
    "            print\n",
    "            finished_processes.append(p)\n",
    "        # otherwise, process finished successfully\n",
    "        # Print out total run-time\n",
    "        else:\n",
    "            p[\"end_time\"] = time.time()\n",
    "            print \"Finished Docking\", p[\"in\"], \"in\", (p[\"end_time\"] - p[\"start_time\"])\n",
    "            os.system(\"mv {0} {1}\".format(p[\"out_f\"], p[\"out_f\"].replace(\"_in_progress\", \"\")))\n",
    "            finished_processes.append(p)\n",
    "    \n",
    "    # Update active process list\n",
    "    processes = new_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill everything left just in case\n",
    "for p in finished_processes:\n",
    "    try:\n",
    "        p[\"p\"].terminate()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585a42f7bb1c4e72b63e37dc4f9c4f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse Ligand Docking Results\n",
    "#\n",
    "# Reads in all docking results from N independent trials and creates\n",
    "# a ranked poses describing the top 100 scoring poses accross all\n",
    "# trials for each drug-target pair. Also creates a single .pdb under\n",
    "# docked_ligands that contains these 100 top poses in one .pdb\n",
    "#\n",
    "for drug, uni in tqdm_notebook(drug_pairs[~pd.isnull(drug_pairs[\"Human ID\"])][[\"Compound Name\", \"Human ID\"]].values):\n",
    "    # Parse Inputs\n",
    "    drug = drug.replace(\"-\", \"_\").replace(\" \", \"_\").split(\"(\")[0]\n",
    "    drug_f = glob.glob(\"{0}/Ligands/{1}*\".format(output_dir, drug))[0]\n",
    "    \n",
    "    try:\n",
    "        uni_f = glob.glob(\"{0}/Undocked_Structures/{1}*\".format(output_dir, uni))[0]\n",
    "    except IndexError:\n",
    "        continue\n",
    "    \n",
    "    # Load all docking sub-batches\n",
    "    outs = glob.glob(\"{0}/Docked_Ligands/sub_batches/{1}_{2}_*.pdb\".format(output_dir, uni, drug))\n",
    "    \n",
    "    if(len(outs) == 0):\n",
    "        continue\n",
    "    \n",
    "    # Read in all docked poses\n",
    "    model2data = dict()\n",
    "    for out in outs:\n",
    "        with open(out, \"r\") as f:\n",
    "            for l in f:\n",
    "                if(l[:6] == \"MODEL \"):\n",
    "                    model = (out, int(l.strip().split()[-1]))\n",
    "                    lines = [\"MODELSTART\\n\"]\n",
    "                    socre = 0\n",
    "                    centroid = np.zeros(3)\n",
    "                    n_atoms = 0\n",
    "                elif(l[:6] == \"REMARK\"):\n",
    "                    score = float(l.strip().split()[-1])\n",
    "                    lines.append(l)\n",
    "                elif(l[:6] == \"COMPND\"):\n",
    "                    lines.append(l.replace(\"UNNAMED\", drug.upper()))\n",
    "                elif(l[:6] == \"HETATM\"):\n",
    "                    lines.append(l)\n",
    "                    centroid += np.array([float(l[30:38]), float(l[38:46]), float(l[46:54])])\n",
    "                    n_atoms += 1\n",
    "                elif(l[:6] == \"END   \"):\n",
    "                    lines.append(l)\n",
    "                elif(l[:6] == \"ENDMDL\"):\n",
    "                    lines.append(l)\n",
    "                    model2data[model] = (lines, score, centroid / float(n_atoms))\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    # Select top poses from \"distinct\" binding sites\n",
    "    #out = open(\"Docked_Ligands/{0}_{1}.pdb\".format(uni, drug), \"w+\")\n",
    "    model_num = 1\n",
    "    cur_centroids = []\n",
    "    out = open(\"{0}/Docked_Ligands/{1}_{2}.pdb\".format(output_dir, uni, drug), \"w+\")\n",
    "    for k, v in sorted(model2data.iteritems(), key=lambda (k, v): v[1]):\n",
    "        if(len(cur_centroids) == 0):\n",
    "            out2 = open(\"{0}/Docked_Ligands/ranked_poses/{1}_{2}_{3}.pdb\".format(output_dir, uni, drug, model_num), \"w+\")\n",
    "            out.write(\"\".join(v[0]).replace(\"MODELSTART\", \"MODEL{0:>9}\".format(model_num)))\n",
    "            out2.write(\"\".join(v[0]).replace(\"MODELSTART\", \"MODEL{0:>9}\".format(model_num)))\n",
    "            out2.close()\n",
    "            model_num += 1\n",
    "            cur_centroids.append(v[2])\n",
    "        elif(min([distance.euclidean(v[2], x) for x in cur_centroids]) >= 1):\n",
    "            out2 = open(\"{0}/Docked_Ligands/ranked_poses/{1}_{2}_{3}.pdb\".format(output_dir, uni, drug, model_num), \"w+\")\n",
    "            out.write(\"\".join(v[0]).replace(\"MODELSTART\", \"MODEL{0:>9}\".format(model_num)))\n",
    "            out2.write(\"\".join(v[0]).replace(\"MODELSTART\", \"MODEL{0:>9}\".format(model_num)))\n",
    "            out2.close()\n",
    "            model_num += 1\n",
    "            cur_centroids.append(v[2])\n",
    "        if(model_num > 100):\n",
    "            break\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e796e8bc104d868094aa8f0ee86172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse Ligand Docking Results\n",
    "#\n",
    "# Read in all scores accross all trials for each drug-target pair\n",
    "#\n",
    "pair2scores = dict()\n",
    "for drug, uni in tqdm_notebook(drug_pairs[~pd.isnull(drug_pairs[\"Human ID\"])][[\"Compound Name\", \"Human ID\"]].values):\n",
    "    # Parse Inputs\n",
    "    drug = drug.replace(\"-\", \"_\").replace(\" \", \"_\").split(\"(\")[0]\n",
    "    drug_f = glob.glob(\"{0}/Ligands/{1}*\".format(output_dir, drug))[0]\n",
    "    \n",
    "    try:\n",
    "        uni_f = glob.glob(\"{0}/Undocked_Structures/{1}*\".format(output_dir, uni))[0]\n",
    "    except IndexError:\n",
    "        continue\n",
    "    \n",
    "    # Load all docking sub-batches\n",
    "    outs = glob.glob(\"{0}/Docked_Ligands/sub_batches/{1}_{2}_*.pdb\".format(output_dir, uni, drug))\n",
    "    \n",
    "    if(len(outs) == 0):\n",
    "        continue\n",
    "    \n",
    "    scores = sorted(flatten([[float(x.split()[-1]) for x in sp.check_output(\"grep minimizedAffinity \" + out, shell=True).split(\"\\n\") if not x == \"\"] for out in outs]))\n",
    "    \n",
    "    pair2scores[(drug, uni)] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
